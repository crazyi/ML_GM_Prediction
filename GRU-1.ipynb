{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T11:01:17.998278Z",
     "start_time": "2024-12-24T11:01:01.660762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 数据读取\n",
    "df_train = pd.read_csv('训练集.csv')  # 训练集文件名\n",
    "df_val = pd.read_csv('验证集.csv')   # 验证集文件名\n",
    "\n",
    "# 数据标准化\n",
    "scaler_coords = StandardScaler()  # 标准化经度、纬度\n",
    "scaler_value = StandardScaler()   # 标准化 value\n",
    "df_train[['longitude', 'latitude']] = scaler_coords.fit_transform(df_train[['longitude', 'latitude']])\n",
    "df_train['value'] = scaler_value.fit_transform(df_train[['value']])\n",
    "\n",
    "df_val[['longitude', 'latitude']] = scaler_coords.transform(df_val[['longitude', 'latitude']])  # 用训练集的标准化器\n",
    "df_val['value'] = scaler_value.transform(df_val[['value']])  # 用训练集的标准化器\n",
    "\n",
    "# 提取输入和目标值\n",
    "X_train = df_train[['longitude', 'latitude']].values\n",
    "y_train = df_train['value'].values\n",
    "\n",
    "X_val = df_val[['longitude', 'latitude']].values\n",
    "y_val = df_val['value'].values\n",
    "\n",
    "# 将数据转换为 PyTorch Tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "# 定义 GRU 模型\n",
    "class GRUPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(GRUPredictor, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 超参数设置\n",
    "input_dim = 2  # 输入特征维度: longitude 和 latitude\n",
    "hidden_dim = 64  # GRU 隐层维度\n",
    "output_dim = 1  # 输出维度: value\n",
    "num_layers = 3  # GRU 层数\n",
    "epochs = 2000  # 训练轮次\n",
    "learning_rate = 0.001  # 学习率\n",
    "\n",
    "# 初始化 GRU 模型\n",
    "model = GRUPredictor(input_dim, hidden_dim, output_dim, num_layers).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 模型训练\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}\")\n",
    "\n",
    "# 模型验证\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_val = model(X_val_tensor).cpu().numpy()\n",
    "    y_val_actual = y_val_tensor.cpu().numpy()\n",
    "\n",
    "# 反标准化处理\n",
    "predictions_original = scaler_value.inverse_transform(y_pred_val)\n",
    "actual_values_original = scaler_value.inverse_transform(y_val_actual)\n",
    "coords_val_original = scaler_coords.inverse_transform(X_val)\n",
    "\n",
    "# 保存结果\n",
    "df_result = pd.DataFrame({\n",
    "    'longitude': np.round(coords_val_original[:, 0], 6),\n",
    "    'latitude': np.round(coords_val_original[:, 1], 6),\n",
    "    'actual_value': np.round(actual_values_original.flatten(), 2),\n",
    "    'predicted_value': np.round(predictions_original.flatten(), 2)\n",
    "})\n",
    "\n",
    "df_result.to_csv('predictions-gru.csv', index=False)\n",
    "print(\"训练完成，结果已保存至 'predictions-gru.csv'\")\n"
   ],
   "id": "e4854e113b45714e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch [20/2000], Loss: 0.983982\n",
      "Epoch [40/2000], Loss: 0.966633\n",
      "Epoch [60/2000], Loss: 0.952057\n",
      "Epoch [80/2000], Loss: 0.922590\n",
      "Epoch [100/2000], Loss: 0.878331\n",
      "Epoch [120/2000], Loss: 0.845706\n",
      "Epoch [140/2000], Loss: 0.825468\n",
      "Epoch [160/2000], Loss: 0.803782\n",
      "Epoch [180/2000], Loss: 0.750030\n",
      "Epoch [200/2000], Loss: 0.671762\n",
      "Epoch [220/2000], Loss: 0.627460\n",
      "Epoch [240/2000], Loss: 0.557614\n",
      "Epoch [260/2000], Loss: 0.441442\n",
      "Epoch [280/2000], Loss: 0.348936\n",
      "Epoch [300/2000], Loss: 0.301305\n",
      "Epoch [320/2000], Loss: 0.265435\n",
      "Epoch [340/2000], Loss: 0.235128\n",
      "Epoch [360/2000], Loss: 0.209758\n",
      "Epoch [380/2000], Loss: 0.190649\n",
      "Epoch [400/2000], Loss: 0.173111\n",
      "Epoch [420/2000], Loss: 0.154621\n",
      "Epoch [440/2000], Loss: 0.137867\n",
      "Epoch [460/2000], Loss: 0.125641\n",
      "Epoch [480/2000], Loss: 0.117034\n",
      "Epoch [500/2000], Loss: 0.110900\n",
      "Epoch [520/2000], Loss: 0.106427\n",
      "Epoch [540/2000], Loss: 0.101473\n",
      "Epoch [560/2000], Loss: 0.096935\n",
      "Epoch [580/2000], Loss: 0.092380\n",
      "Epoch [600/2000], Loss: 0.087607\n",
      "Epoch [620/2000], Loss: 0.082549\n",
      "Epoch [640/2000], Loss: 0.077823\n",
      "Epoch [660/2000], Loss: 0.072480\n",
      "Epoch [680/2000], Loss: 0.067125\n",
      "Epoch [700/2000], Loss: 0.061704\n",
      "Epoch [720/2000], Loss: 0.056360\n",
      "Epoch [740/2000], Loss: 0.051313\n",
      "Epoch [760/2000], Loss: 0.048064\n",
      "Epoch [780/2000], Loss: 0.043469\n",
      "Epoch [800/2000], Loss: 0.040315\n",
      "Epoch [820/2000], Loss: 0.037848\n",
      "Epoch [840/2000], Loss: 0.036292\n",
      "Epoch [860/2000], Loss: 0.034052\n",
      "Epoch [880/2000], Loss: 0.032564\n",
      "Epoch [900/2000], Loss: 0.031278\n",
      "Epoch [920/2000], Loss: 0.030160\n",
      "Epoch [940/2000], Loss: 0.030166\n",
      "Epoch [960/2000], Loss: 0.028450\n",
      "Epoch [980/2000], Loss: 0.027570\n",
      "Epoch [1000/2000], Loss: 0.026835\n",
      "Epoch [1020/2000], Loss: 0.026155\n",
      "Epoch [1040/2000], Loss: 0.025521\n",
      "Epoch [1060/2000], Loss: 0.026400\n",
      "Epoch [1080/2000], Loss: 0.024513\n",
      "Epoch [1100/2000], Loss: 0.023840\n",
      "Epoch [1120/2000], Loss: 0.023313\n",
      "Epoch [1140/2000], Loss: 0.022812\n",
      "Epoch [1160/2000], Loss: 0.022390\n",
      "Epoch [1180/2000], Loss: 0.021964\n",
      "Epoch [1200/2000], Loss: 0.021426\n",
      "Epoch [1220/2000], Loss: 0.020976\n",
      "Epoch [1240/2000], Loss: 0.020543\n",
      "Epoch [1260/2000], Loss: 0.020173\n",
      "Epoch [1280/2000], Loss: 0.020421\n",
      "Epoch [1300/2000], Loss: 0.019356\n",
      "Epoch [1320/2000], Loss: 0.018952\n",
      "Epoch [1340/2000], Loss: 0.018567\n",
      "Epoch [1360/2000], Loss: 0.018194\n",
      "Epoch [1380/2000], Loss: 0.017825\n",
      "Epoch [1400/2000], Loss: 0.019626\n",
      "Epoch [1420/2000], Loss: 0.017228\n",
      "Epoch [1440/2000], Loss: 0.016797\n",
      "Epoch [1460/2000], Loss: 0.016455\n",
      "Epoch [1480/2000], Loss: 0.016124\n",
      "Epoch [1500/2000], Loss: 0.015797\n",
      "Epoch [1520/2000], Loss: 0.019215\n",
      "Epoch [1540/2000], Loss: 0.015562\n",
      "Epoch [1560/2000], Loss: 0.014933\n",
      "Epoch [1580/2000], Loss: 0.014588\n",
      "Epoch [1600/2000], Loss: 0.014301\n",
      "Epoch [1620/2000], Loss: 0.014018\n",
      "Epoch [1640/2000], Loss: 0.013740\n",
      "Epoch [1660/2000], Loss: 0.013467\n",
      "Epoch [1680/2000], Loss: 0.014655\n",
      "Epoch [1700/2000], Loss: 0.013261\n",
      "Epoch [1720/2000], Loss: 0.012716\n",
      "Epoch [1740/2000], Loss: 0.012463\n",
      "Epoch [1760/2000], Loss: 0.012222\n",
      "Epoch [1780/2000], Loss: 0.011987\n",
      "Epoch [1800/2000], Loss: 0.011756\n",
      "Epoch [1820/2000], Loss: 0.014466\n",
      "Epoch [1840/2000], Loss: 0.011635\n",
      "Epoch [1860/2000], Loss: 0.011121\n",
      "Epoch [1880/2000], Loss: 0.010910\n",
      "Epoch [1900/2000], Loss: 0.010711\n",
      "Epoch [1920/2000], Loss: 0.010516\n",
      "Epoch [1940/2000], Loss: 0.010324\n",
      "Epoch [1960/2000], Loss: 0.010137\n",
      "Epoch [1980/2000], Loss: 0.010794\n",
      "Epoch [2000/2000], Loss: 0.009872\n",
      "训练完成，结果已保存至 'predictions-gru.csv'\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
